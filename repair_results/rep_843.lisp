DEFAULT number of episodes per experiment n episodes 30 n max steps 500 hold actions for a given number of steps n hold action 1 action modes 8 landing pitch roll throttle yaw 7 landing throttle 6 landing pitch roll 5 landing pitch roll throttle 4 col avoidance pitch yaw 3 col avoidance p tch roll yaw 2 col avoidance pitch roll 1 col avoidance roll only n act mode 8 action level low ( 0 angles ) high ( 1 velocity ) higher ( 2 position ) action level 1 define what reward source we are using joystick reward network reward source custom high ( images ) or low level ( encoded images + vehicle states ) feature level low select mission collision avoidance landing mission landing turn gps on/off ( x and y position with respect to initial player location ) use gps True use either sparse or dense reward reward function sparse use or not wind use wind True use perception module or the ground truth for the landing pad use perception True enable pyqt gui use pyqt True UAS camera parameters ( make sure it matches the settings file ) screen width 320 screen height 240 scale input images for processing ( scale observation array ) scale input True scale factor 0.25 rgba rgb grayscale depth camera mode rgb if want to return observation as images or flat arrays flat images False defines we wants to save all images and depth data while training save training image data False attitude parameters alt * -6 when n act mode 1 need to define constant action in x ( radians ) const act x -0.5 when n act mode 6 need to define constant landing throttle const act z 0.5 define if the human start controlling ( or the learning agent ) initial human control False MAP map size max x 115 min x -2 <EOF>